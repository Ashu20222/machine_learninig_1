{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef2da16",
   "metadata": {},
   "source": [
    "# Univariate Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b15e3",
   "metadata": {},
   "source": [
    "## Finding the Best Fit Sigmoid Curve - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966de56b",
   "metadata": {},
   "source": [
    "Likelihood\n",
    "Now, let’s say that for the ten points in our example, the labels are as follows:\n",
    "\n",
    "Point no.\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\n",
    "Diabetes\tno\tno\tno\tyes\tno\tyes\tyes\tyes\tyes\tyes\n",
    "In this case, the likelihood would be equal to:\n",
    "\n",
    "\n",
    "(1−P1) (1−P2 ) (1−P3) (1−P5 ) (P4) (P6) (P7) (P8) (P9) (P10)     ✓ Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17e492",
   "metadata": {},
   "source": [
    "## Odds and Log Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535370db",
   "metadata": {},
   "source": [
    "Log Odds\n",
    "So, let’s say that the equation for the log odds is:\n",
    "\n",
    " \n",
    "For x = 220, the log odds are equal to -13.5+(0.06*220) = -0.3. For x = 231.5, log odds are equal to:\n",
    "    \n",
    "ans: 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367310c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6858d583",
   "metadata": {},
   "source": [
    "Log Odds\n",
    "So, let’s say that the equation for log odds is:\n",
    "\n",
    " \n",
    "For x = 220, the log odds are equal to -0.3 and for x = 231.5, the log odds are equal to 0.39. For x = 243, the log odds are equal to:\n",
    "    \n",
    "ans: 1.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc5f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0a8f8d",
   "metadata": {},
   "source": [
    "# Multivariate Logistic Regression - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69bcdaa",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040beb1",
   "metadata": {},
   "source": [
    "Level counts\n",
    "In the text above, you saw that for the variable ‘MultipleLines’ the value counts of the levels ‘Yes’, ‘No’, and ‘No phone service’ are 3390, 2971, and 682 respectively. When you run the same command for the column ‘OnlineBackup’, what will the value count for its level ‘No internet service’ turn out to be?\n",
    "\n",
    "\n",
    "1526   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf4078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec239c09",
   "metadata": {},
   "source": [
    "Levels of Dummy Variables\n",
    "If you check the value counts of the levels ‘OnlineBackup’, ‘OnlineSecurity’, ‘DeviceProtection’, and all the others for which one of the levels was dropped manually, you can see that the count of the level ‘No internet service’ is the same for all, i.e. 1526. Can you explain briefly why this has happened?\n",
    "\n",
    "ans: This happens because the level ‘No internet service’ just tells you whether a user has internet service or not. Now because the number of users not having an internet service is the same, the count of this level in all of these variables will be the same. You can also check the value counts of the variable ‘InternetService’ and you’ll see that the output you’ll get is:\n",
    "\n",
    "Fiber Optic    3096\n",
    "DSL                   2421\n",
    "No                      1526\n",
    "\n",
    "Coincidence? No! \n",
    "This information is already contained in the variable ‘InternetService’ and hence, the count will be the same in all the variables with the level ‘No internet service’. This is actually also the reason we chose to drop this particular level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452e173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f272b0de",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation - II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fecb5",
   "metadata": {},
   "source": [
    "Standardising Variables\n",
    "In a dataset with mean 50 and standard deviation 12, what will be the value of a variable with an initial value of 20 after you standardise it?\n",
    "\n",
    "\n",
    "1.9\n",
    "\n",
    "\n",
    "-1.9\n",
    "\n",
    "\n",
    "2.5\n",
    "\n",
    "\n",
    "-2.5   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b84a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355e7f0a",
   "metadata": {},
   "source": [
    "Standardising the train and test sets\n",
    "As Rahim mentioned in the lecture, you use 'fit_transform' on the train set but just 'transform' on the test set. Recall you had learnt this in linear regression as well. Why do you think this is done?\n",
    "\n",
    "\n",
    "Suggested Answer\n",
    "The 'fit_transform'  command first fits the data to have a mean of 0 and a standard deviation of 1, i.e. it scales all the variables using:\n",
    "\n",
    "\n",
    "Now, once this is done, all the variables are transformed using this formula. Now, when you go ahead to the test set, you want the variables to not learn anything new. You want to use the old centralisation that you had when you used fit on the train dataset. And this is why you don't apply 'fit' on the test data, just the 'transform'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a6de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99e18277",
   "metadata": {},
   "source": [
    "## Building your First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a2557",
   "metadata": {},
   "source": [
    "Correlation Table\n",
    "Which of the following command can be used to view the correlation table for the dataframe telecom?\n",
    "\n",
    "\n",
    "telecom.corr()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b1e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45b75e0",
   "metadata": {},
   "source": [
    "Checking Correlations\n",
    "Take a look at the heatmap provided above. Which of the variables have the highest correlation between them?\n",
    "\n",
    "\n",
    "StreamingTV_Yes and StreamingMovies_Yes\n",
    "\n",
    "\n",
    "StreamingTV_No and StreamingMovies_No\n",
    "\n",
    "\n",
    "MultipleLines_No and MultipleLines_Yes   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6081c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a49d36",
   "metadata": {},
   "source": [
    "Significant Variables\n",
    "Which of the following variables are insignificant as of now based on the summary statistics above? (More than one option may be correct.)\n",
    "\n",
    "Note: Use p-value to determine the insignificant variables.\n",
    "\n",
    "\n",
    "PhoneService   ✓ Correct\n",
    "\n",
    "MultipleLines_Yes\n",
    "\n",
    "TechSupport_Yes   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a025ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a60f64ce",
   "metadata": {},
   "source": [
    "Negatively Correlated Variables\n",
    "Which of the following variables are negatively correlated with the target variable based on the summary statistics given above? (More than one option may be correct.)\n",
    "\n",
    "\n",
    "tenure    ✓ Correct\n",
    "\n",
    "TotalCharges\n",
    "\n",
    "MonthlyCharges    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1532a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ef13d9",
   "metadata": {},
   "source": [
    "p-values\n",
    "After learning the coefficients of each variable, the model also produces a ‘p-value’ of each coefficient. Fill in the blanks so that the statement is correct: \n",
    "\n",
    "“The null hypothesis is that the coefficient is __. If the p-value is small, you can say that the coefficient is significant and hence the null hypothesis ____.”\n",
    "\n",
    "\n",
    "zero, can be rejected    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d63e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "046397ac",
   "metadata": {},
   "source": [
    "## Feature Elimination using RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e560ee",
   "metadata": {},
   "source": [
    "Threshold Value\n",
    "You saw that Rahim chose a cut-off of 0.5. What can be said about this threshold?\n",
    "\n",
    "\n",
    "It was arbitrarily chosen by us, i.e. there’s nothing special about 0.5. We could have chosen something else as well.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2f4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0319becd",
   "metadata": {},
   "source": [
    "Significance based on RFE\n",
    "Based on the RFE output shown above, which of the variables is least significant?\n",
    "\n",
    "\n",
    "OnlineBackup_Yes\n",
    "\n",
    "\n",
    "Partner\n",
    "\n",
    "\n",
    "gender_Male    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b204008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "481fc6b3",
   "metadata": {},
   "source": [
    "Churn based on Threshold\n",
    "Suppose the following table shows the predicted values for the probabilities for 'Churn'. Assuming you chose an arbitrary cut-off of 0.5 wherein a probability of greater than 0.5 means the customer would churn and a probability of less than or equal 0.5 means the customer wouldn't churn, which of these customers do you think will churn? (More than one option may be correct.)\n",
    "\n",
    "Customer\tProbability(Churn)\n",
    "A\t0.45\n",
    "B\t0.67\n",
    "C\t0.98\n",
    "D\t0.49\n",
    "E\t0.03\n",
    "\n",
    "A\n",
    "\n",
    "\n",
    "B   ✓ Correct\n",
    "\n",
    "C   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89ef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bbd90f5",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae520f",
   "metadata": {},
   "source": [
    "Confusion Matrix and Accuracy\n",
    "Given the confusion matrix below, can you tell how many 'Churns' were correctly identified, i.e. if the person has actually churned, it is predicted as a churn?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t80\t30\n",
    "Churn\t20\t70\n",
    " \n",
    "\n",
    "\n",
    "80\n",
    "\n",
    "\n",
    "30\n",
    "\n",
    "\n",
    "20\n",
    "\n",
    "\n",
    "70   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f136e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c182b171",
   "metadata": {},
   "source": [
    "Calculating Accuracy\n",
    "From the confusion matrix you saw in the last question, compute the accuracy of the model.\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t80\t30\n",
    "Churn\t20\t70\n",
    "\n",
    "70%\n",
    "\n",
    "\n",
    "75%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d361c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a599aacb",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "Suppose you built a logistic regression model to predict whether a patient has lung cancer or not and you get the following confusion matrix as the output.\n",
    "\n",
    "Actual/Predicted\tNo\tYes\n",
    "No\t400\t100\n",
    "Yes\t50\t150\n",
    "How many of the patients were wrongly identified as a 'Yes'?\n",
    "\n",
    "\n",
    "400\n",
    "\n",
    "\n",
    "100   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef43c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3c42d92",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "Take a look at the table again.\n",
    "\n",
    "Actual/Predicted\tNo\tYes\n",
    "No\t400\t100\n",
    "Yes\t50\t150\n",
    "How many of these patients were correctly labelled, i.e. if the patient had lung cancer it was actually predicted as a 'Yes' and if they didn't have lung cancer, it was actually predicted as a 'No'?\n",
    "\n",
    "\n",
    "150\n",
    "\n",
    "\n",
    "400\n",
    "\n",
    "\n",
    "500\n",
    "\n",
    "\n",
    "550   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea837f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7937a53",
   "metadata": {},
   "source": [
    "Accuracy Calculation\n",
    "From the table you used for the last two questions, what will be the accuracy of the model?\n",
    "\n",
    "Actual/Predicted\tNo\tYes\n",
    "No\t400\t100\n",
    "Yes\t50\t150\n",
    "\n",
    "57.14%\n",
    "\n",
    "\n",
    "64.29%\n",
    "\n",
    "\n",
    "71.43%\n",
    "\n",
    "\n",
    "78.57%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99899b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8457f71",
   "metadata": {},
   "source": [
    "## Manual Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1e0c3",
   "metadata": {},
   "source": [
    "Multivariate Logistic Regression (Variable Selection)\n",
    "Based on the above information, what can you say about the log odds of these two customers? \n",
    "\n",
    "PS: Recall the log odds for univariate logistic regression was given as:\n",
    "\n",
    " \n",
    "\n",
    "log odds (customer A) < log odds (customer B)\n",
    "\n",
    "\n",
    "log odds (customer A) = log odds (customer B)\n",
    "\n",
    "\n",
    "log odds (customer A) > log odds (customer B)    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c1b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5765991e",
   "metadata": {},
   "source": [
    "Multivariate Logistic Regression (Variable Selection)\n",
    "Now, what can you say about the odds of churn for these two customers?\n",
    "\n",
    "\n",
    "For customer A, the odds of churning are lower than for customer B\n",
    "\n",
    "\n",
    "For customer A, the odds of churning are equal to those for customer B\n",
    "\n",
    "\n",
    "For customer A, the odds of churning are higher than for customer B    ✓ Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124b18f",
   "metadata": {},
   "source": [
    "Multivariate Logistic Regression - Log Odds\n",
    "Now, suppose two customers, customer C and customer D, are such that their behaviour is exactly the same, except for the fact that customer C has OnlineSecurity, while customer D does not. What can you say about the odds of churn for these two customers?\n",
    "\n",
    "\n",
    "For customer C, the odds of churning are lower than for customer D    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6789a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f52ef12",
   "metadata": {},
   "source": [
    "## Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4178aa0",
   "metadata": {},
   "source": [
    "Logistic Regression in Python\n",
    "Which of these methods is used for fitting a logistic regression model using statsmodels?\n",
    "\n",
    "\n",
    "OLS()\n",
    "\n",
    "\n",
    "GLM()    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e3268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "995a507b",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "Given the following confusion matrix, calculate the accuracy of the model.\n",
    "\n",
    "Actual/Predicted\tNos\tYeses\n",
    "Nos\t1000\t50\n",
    "Yeses\t250\t1200\n",
    "\n",
    "96%\n",
    "\n",
    "\n",
    "88%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ec878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733b7e29",
   "metadata": {},
   "source": [
    "Diabetic based on Threshold\n",
    "Suppose you are building a logistic regression model to determine whether a person has diabetes or not. Following are the values of predicted probabilities of 10 patients.\n",
    "\n",
    "4\n",
    "\n",
    "\n",
    "5\n",
    "\n",
    "\n",
    "6    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397d9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ecd3fb",
   "metadata": {},
   "source": [
    "Log Odds\n",
    "Suppose you are working for a media services company like Netflix. They're launching a new show called 'Sacred Games' and you are building a logistic regression model which will predict whether a person will like it or not based on whether consumers have liked/disliked some previous shows. You have the data of five of the previous shows and you're just using the dummy variables for these five shows to build the model. If the variable is 1, it means that the consumer liked the show and if the variable is zero, it means that the consumer didn't like the show. The following table shows the values of the coefficients for these five shows that you got after building the logistic regression model.\n",
    "\n",
    " \n",
    "\n",
    "Variable Name\tCoefficient Value\n",
    "TrueDetective_Liked\t0.47\n",
    "ModernFamily_Liked\t-0.45\n",
    "Mindhunter_Liked\t0.39\n",
    "Friends_Liked\t-0.23\n",
    "Narcos_Liked\t0.55\n",
    " \n",
    "\n",
    "Now, you have the data of three consumers Reetesh, Kshitij, and Shruti for these 5 shows indicating whether or not they liked these shows. This is shown in the table below:\n",
    "\n",
    "Based on this data, which one of these three consumers is most likely to like to new show 'Sacred Games'?\n",
    "\\\n",
    "\n",
    "\n",
    "Reetesh   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5d577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55b62dae",
   "metadata": {},
   "source": [
    "# Multivariate Logistic Regression - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185b04f",
   "metadata": {},
   "source": [
    "## Metrics Beyond Accuracy: Sensitivity & Specificity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613467b",
   "metadata": {},
   "source": [
    "False Positives\n",
    "What is the number of False Positives for the model given below?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t400\t100\n",
    "Churn\t50\t150\n",
    " \n",
    "\n",
    "\n",
    "400\n",
    "\n",
    "\n",
    "100    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e74a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a96e94e",
   "metadata": {},
   "source": [
    "Sensitivity\n",
    "Sensitivity is defined as the fraction of the number of correctly predicted positives and the total number of actual positives, i.e.\n",
    "\n",
    "\n",
    "What is the sensitivity of the following model?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t400\t100\n",
    "Churn\t50\t150\n",
    " \n",
    "\n",
    "\n",
    "60%\n",
    "\n",
    "\n",
    "75%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d2b78b2",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "Among the three metrics that you've learnt about, which one is the highest for the model below?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t400\t100\n",
    "Churn\t50\t150\n",
    "\n",
    "Accuracy\n",
    "\n",
    "\n",
    "Sensitivity\n",
    "\n",
    "\n",
    "Specificity   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911236f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc15a32",
   "metadata": {},
   "source": [
    "## Sensitivity and Specificity in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca48a",
   "metadata": {},
   "source": [
    "False Negatives\n",
    "What is the number of False Negatives for the model given below?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t80\t40\n",
    "Churn\t30\t50\n",
    " \n",
    "\n",
    "\n",
    "80\n",
    "\n",
    "\n",
    "40\n",
    "\n",
    "\n",
    "30   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92d38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ecf03bf",
   "metadata": {},
   "source": [
    "Specificity\n",
    "Specificity is defined as the fraction of the number of correctly predicted negatives and the total number of actual negatives, i.e.\n",
    "\n",
    "What is the approximate specificity of the following model?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t80\t40\n",
    "Churn\t30\t50\n",
    "\n",
    "60%\n",
    "\n",
    "\n",
    "67%   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80178016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceb78cd4",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "Which among accuracy, sensitivity, and specificity is the highest for the model below?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t80\t40\n",
    "Churn\t30\t50\n",
    "\n",
    "Accuracy\n",
    "\n",
    "\n",
    "Sensitivity\n",
    "\n",
    "\n",
    "Specificity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7d4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbd5d420",
   "metadata": {},
   "source": [
    "Other Metrics\n",
    "In the code, you saw Rahim evaluate some other metrics as well. These were:\n",
    "\n",
    "\n",
    "As you can see, the 'False Positive Rate' is basically (1 - Specificity). Check the formula and the values in the code to verify.\n",
    "The positive predictive value is the number of positives correctly predicted by the total number of positives predicted. This is also known as 'Precision' which you'll learn more about soon.\n",
    "Similarly, the negative predictive value is the number of negatives correctly predicted by the total number of negatives predicted. There's no particular term for this as such.\n",
    "Calculate the given three metrics for the model below and identify which one is the largest among them.\n",
    "\n",
    "Negative Predictive Value    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da837e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9117e333",
   "metadata": {},
   "source": [
    "## Understanding ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70393c",
   "metadata": {},
   "source": [
    "TPR and FPR\n",
    "Given the following confusion matrix, calculate the value of True Positive Rate (TPR) and False Positive Rate (FPR).\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t300\t200\n",
    "Churn\t100\t400\n",
    "\n",
    "TPR = 40%\n",
    "\n",
    "FPR = 80%\n",
    "\n",
    "\n",
    "TPR = 40%\n",
    "\n",
    "FPR = 60%\n",
    "\n",
    "\n",
    "TPR = 80%\n",
    "\n",
    "FPR = 40%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702837e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2382f2e",
   "metadata": {},
   "source": [
    "True Positive Rate\n",
    "You have the following table showcasing the actual 'Churn' labels and the predicted probabilities for 5 customers.\n",
    "\n",
    " \n",
    "\n",
    "Customer\tChurn\tPredicted Churn Probability\n",
    "Thulasi\t1\t0.52\n",
    "Aditi\t0\t0.56\n",
    "Jaideep\t1\t0.78\n",
    "Ashok\t0\t0.45\n",
    "Amulya\t0\t0.22\n",
    " \n",
    "\n",
    "Calculate the True Positive Rate and False Positive rate for the cutoffs of 0.4 and 0.5. Which of these cutoffs, will give you a better model?\n",
    "\n",
    "Note: The good model is the one in which TPR is high and FPR is low.\n",
    "\n",
    "\n",
    "Cutoff of 0.4\n",
    "\n",
    "\n",
    "Cutoff of 0.5     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22371f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05545349",
   "metadata": {},
   "source": [
    "Changing the Threshold\n",
    "You initially chose a threshold of 0.5 wherein a churn probability of greater than 0.5 would result in the customer being identified as 'Churn' and a churn probability of lesser than 0.5 would result in the customer being identified as 'Not Churn'. \n",
    "\n",
    "Now, suppose you decreased the threshold to a value of 0.3. What will be its effect on the classification?\n",
    "\n",
    "\n",
    "More customers would now be classified as 'Churn'.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45da3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb4b0dc",
   "metadata": {},
   "source": [
    "TPR and FPR\n",
    "Fill in the blanks:\n",
    "\n",
    "When the value of TPR increases, the value of FPR ______. \n",
    "\n",
    "\n",
    "increases    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dd0a48e",
   "metadata": {},
   "source": [
    "Area Under the Curve\n",
    "You have the following five AUCs (Area under the curve) for ROCs plotted for five different models. Which of these models is the best?\n",
    "\n",
    "Model\tAUC\n",
    "A\t0.54\n",
    "B\t0.82\n",
    "C\t0.79\n",
    "D\t0.66\n",
    "E\t0.56\n",
    "\n",
    "A\n",
    "\n",
    "\n",
    "B    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6761669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb2ef27c",
   "metadata": {},
   "source": [
    "## ROC Curve in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d7519",
   "metadata": {},
   "source": [
    "ROC Curve\n",
    "Following is the ROC curve that you got.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "As you can see, when the 'True Positive Rate' is 0.8, the 'False Positive Rate' is about 0.24. What will be the value of specificity, then?\n",
    "\n",
    "0.8\n",
    "\n",
    "\n",
    "0.2\n",
    "\n",
    "\n",
    "0.76    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a902721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3548756",
   "metadata": {},
   "source": [
    "ROC Curve\n",
    "Which of the following ROC curve represents the best model?\n",
    "\n",
    "A\n",
    "\n",
    "\n",
    "B\n",
    "\n",
    "\n",
    "C    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fdb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ec61ba",
   "metadata": {},
   "source": [
    "## Finding the Optimal Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3610cb5",
   "metadata": {},
   "source": [
    "Choosing the Optimal Cut-off\n",
    "Suppose you created a dataframe to find out the optimal cut-off point for a model you built. The dataframe looks like the following:\n",
    "\n",
    "Threshold\tProbability\tAccuracy\tSensitivity\tSpecificity\n",
    "0.0\t0.0\t0.21\t1.00\t0.00\n",
    "0.1\t0.1\t0.39\t0.96\t0.22\n",
    "0.2\t0.2\t0.56\t0.88\t0.49\n",
    "0.3\t0.3\t0.59\t0.81\t0.53\n",
    "0.4\t0.4\t0.62\t0.78\t0.63\n",
    "0.5\t0.5\t0.74\t0.73\t0.74\n",
    "0.6\t0.6\t0.81\t0.64\t0.79\n",
    "0.7\t0.7\t0.78\t0.42\t0.83\n",
    "0.8\t0.8\t0.63\t0.21\t0.92\n",
    "0.9\t0.9\t0.56\t0.03\t0.98\n",
    " \n",
    "\n",
    "Based on the table above, what will the approximate value of the optimal cut-off be?\n",
    "\n",
    "\n",
    "0.4\n",
    "\n",
    "\n",
    "0.5    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefd300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b59b1a57",
   "metadata": {},
   "source": [
    "Choosing a model evaluation metric\n",
    "As you learnt, there is usually a trade-off between various model evaluation metrics, and you cannot maximise all of them simultaneously. For e.g., if you increase sensitivity (% of correctly predicted churns), the specificity (% of correctly predicted non-churns) will reduce. \n",
    "\n",
    " \n",
    "\n",
    "Let's say that you are building a telecom churn prediction model with the business objective that your company wants to implement an aggressive customer retention campaign to retain the 'high churn-risk' customers. This is because a competitor has launched extremely low-cost mobile plans, and you want to avoid churn as much as possible by incentivising the customers. Assume that budget is not a constraint.\n",
    "\n",
    " \n",
    "\n",
    "Which of the following metrics should you choose the maximise?\n",
    "\n",
    "\n",
    "Accuracy\n",
    "\n",
    "\n",
    "Sensitivity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d3259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cac4fc0",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dbee8",
   "metadata": {},
   "source": [
    "Accuracy of the Model\n",
    "Using the threshold of 0.3, what is the approximate accuracy of the model now?\n",
    "\n",
    "\n",
    "72%\n",
    "\n",
    "\n",
    "77%   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc147189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3921e9e3",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "Get the confusion matrix after using the cut-off 0.3. What is the number of 'False Negatives' now?\n",
    "\n",
    "\n",
    "2793\n",
    "\n",
    "\n",
    "842\n",
    "\n",
    "\n",
    "283    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b49b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed66ba50",
   "metadata": {},
   "source": [
    "Sensitivity\n",
    "In the last question you saw that in the confusion matrix, the Churns are being captured better now. Using the confusion matrix, can you tell what will the approximate sensitivity of the model now be?\n",
    "\n",
    "\n",
    "67\n",
    "\n",
    "\n",
    "72\n",
    "\n",
    "\n",
    "76\n",
    "\n",
    "\n",
    "78    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca23556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f0d494",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257d595",
   "metadata": {},
   "source": [
    "Calculating Precision\n",
    "Calculate the precision value for the following model.\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t400\t100\n",
    "Churn\t50\t150\n",
    " \n",
    "\n",
    "\n",
    "60%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a562d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb89f07a",
   "metadata": {},
   "source": [
    "F1-score\n",
    "There is a measure known as F1-score which essentially combines both precision and recall. It is the basically the harmonic mean of precision and recall and its formula is given by:\n",
    "\n",
    "\n",
    "The F1-score is useful when you want to look at the performance of precision and recall together.\n",
    "\n",
    "Calculate the F1-score for the model below:\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t400\t100\n",
    "Churn\t50\t150\n",
    "\n",
    "33%\n",
    "\n",
    "\n",
    "67%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24769e1e",
   "metadata": {},
   "source": [
    "Optimal Cut-off\n",
    "When using the sensitivity-specificity tradeoff, you found out that the optimal cutoff point was 0.3. Now, when you plotted the precision-recall tradeoff, you got the following curve:\n",
    "\n",
    "\n",
    "\n",
    "What is the optimal cutoff point according to the curve given above?\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "0.24\n",
    "\n",
    "\n",
    "0.42    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca1dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0ec6fc",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941b686",
   "metadata": {},
   "source": [
    "Calculating Accuracy\n",
    "Recall that in the last segment you saw that the cutoff based on the precision-recall tradeoff curve was approximately 0.42. When you take this cut-off, you get the following confusion matrix on the test set.\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t1294\t234\n",
    "Churn\t223\t359\n",
    "What will the approximate value of accuracy be on the test set now?\n",
    "\n",
    "\n",
    "60%\n",
    "\n",
    "\n",
    "72%\n",
    "\n",
    "\n",
    "75%\n",
    "\n",
    "\n",
    "78%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7cdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e35bd5",
   "metadata": {},
   "source": [
    "Calculating Recall\n",
    "For the confusion matrix you saw in the last question, what will the approximate value of recall be?\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t1294\t234\n",
    "Churn\t223\t359\n",
    "\n",
    "62%    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b4a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75cab69b",
   "metadata": {},
   "source": [
    "## Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9944a4",
   "metadata": {},
   "source": [
    "Calculating Sensitivity\n",
    "Suppose you got the following confusion matrix for a model by using a cutoff of 0.5.\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t1200\t400\n",
    "Churn\t350\t1050\n",
    " \n",
    "\n",
    "Calculate the sensitivity for the model above. Now suppose for the same model, you changed the cutoff from 0.5 to 0.4 such that your number of true positives increased from 1050 to 1190. What will the be the change in sensitivity?\n",
    "\n",
    " \n",
    "\n",
    "Note: Report the answer in terms of new_value - old_value, i.e. if the sensitivity was, say, 0.6 earlier and then changed to 0.8, report it as (0.8 - 0.6), i.e. 0.2.\n",
    "\n",
    "\n",
    "0.05\n",
    "\n",
    "\n",
    "-0.05\n",
    "\n",
    "\n",
    "0.1    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440f871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "997cde23",
   "metadata": {},
   "source": [
    "Calculating Precision\n",
    "Consider the confusion matrix you had in the last question.\n",
    "\n",
    "Actual/Predicted\tNot Churn\tChurn\n",
    "Not Churn\t1200\t400\n",
    "Churn\t350\t1050\n",
    " \n",
    "\n",
    "Calculate the values of precision and recall for the model and determine which of the two is higher.\n",
    "\n",
    "\n",
    "Precision\n",
    "\n",
    "\n",
    "Recall      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eece55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900dab26",
   "metadata": {},
   "source": [
    "True Positive Rate\n",
    "Fill in the blanks.\n",
    "\n",
    "The True Positive Rate (TPR) metric is exactly the same as ______.\n",
    "\n",
    "\n",
    "Sensitivity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58858b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7bf6dc4",
   "metadata": {},
   "source": [
    "Threshold\n",
    "Suppose someone built a logistic regression model to predict whether a person has a heart disease or not. All you have from their model is the following table which contains data of 10 patients.\n",
    "\n",
    "Patient ID\tHeart Disease\tPredicted Probability for Heart Disease\tPredicted Label\n",
    "1001\t0\t0.34\t0\n",
    "1002\t1\t0.58\t1\n",
    "1003\t1\t0.79\t1\n",
    "1004\t0\t0.68\t1\n",
    "1005\t0\t0.21\t0\n",
    "1006\t0\t0.04\t0\n",
    "1007\t1\t0.48\t0\n",
    "1008\t1\t0.64\t1\n",
    "1009\t0\t0.61\t1\n",
    "1010\t1\t0.86\t1\n",
    " \n",
    "\n",
    "Now, you wanted to find out the cutoff based on which the classes were predicted, but you can't. But can you identify which of the following cutoffs would be a valid cutoff for the model above based on the 10 data points given in the table? (More than one option may be correct.)\n",
    "\n",
    "0.50\n",
    "\n",
    "✓ Correct\n",
    "\n",
    "0.55\n",
    "\n",
    "✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be86cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09320a7c",
   "metadata": {},
   "source": [
    "Evaluation Metrics\n",
    "Consider the same model given in the last question.\n",
    "\n",
    "Patient ID\tHeart Disease\tPredicted Probability for Heart Disease\tPredicted Label\n",
    "1001\t0\t0.34\t0\n",
    "1002\t1\t0.58\t1\n",
    "1003\t1\t0.79\t1\n",
    "1004\t0\t0.68\t1\n",
    "1005\t0\t0.21\t0\n",
    "1006\t0\t0.04\t0\n",
    "1007\t1\t0.48\t0\n",
    "1008\t1\t0.64\t1\n",
    "1009\t0\t0.61\t1\n",
    "1010\t1\t0.86\t1\n",
    " \n",
    "\n",
    "Calculate the values of Accuracy, Sensitivity, Specificity, and Precision. Which of these four metrics is the highest for the model?\n",
    "\n",
    "\n",
    "Accuracy\n",
    "\n",
    "\n",
    "Sensitivity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa554d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b3bfda",
   "metadata": {},
   "source": [
    "# Logistic Regression - Industry Applications - Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82f0b7",
   "metadata": {},
   "source": [
    "## Nuances of Logistic Regression - Variable Transformation-II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba930c8",
   "metadata": {},
   "source": [
    "Woe Analysis\n",
    "What information would you infer from the woe trend of tenure variable?\n",
    "\n",
    "\n",
    "As tenure increases, the chances of churning decrease   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424b42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28cf5ea8",
   "metadata": {},
   "source": [
    "Woe Analysis\n",
    "Choose the correct option:\n",
    "\n",
    "\n",
    "Coarse binning is required for tenure variable as there is no monotonic trend in fine binning\n",
    "\n",
    "\n",
    "Coarse binning is not required for tenure variable as there is a clear monotonic trend in fine binning    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cb54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3985221",
   "metadata": {},
   "source": [
    "Woe Analysis\n",
    "What does negative woe signify in 'contract' variable (refer sheet-3)?\n",
    "\n",
    "\n",
    "% of churners (bad customers) are more than % of no-churners (good customers)   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ce340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9f4c3d",
   "metadata": {},
   "source": [
    "Woe Analysis\n",
    "Compare the woe trends of both variables (tenure and contract).\n",
    "\n",
    "Based on the woe trend, which variable when increased in value, might decrease the likelihood of churn?\n",
    "\n",
    "\n",
    "Tenure\n",
    "\n",
    "\n",
    "Contract\n",
    "\n",
    "\n",
    "Both    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072266a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62b7cbde",
   "metadata": {},
   "source": [
    "Information Value\n",
    "What is the total information value of both the variables?\n",
    "\n",
    "\n",
    "Contract = 0.83, Tenure = 1.24\n",
    "\n",
    "Contract = 1.24 , Tenure = 0.83    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769febf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e23d3774",
   "metadata": {},
   "source": [
    "Information Value\n",
    "Choose the correct option?\n",
    "\n",
    "\n",
    "Contract variable has stronger predictive power than tenure    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f09a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "274dbd9a",
   "metadata": {},
   "source": [
    "## Nuances of Logistic Regression - Variable Transformation-III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788c304",
   "metadata": {},
   "source": [
    "WOE Missing Value\n",
    "Woe value for NA bucket is:\n",
    "\n",
    "\n",
    "0.51\n",
    "\n",
    "0.41\n",
    "\n",
    "-0.41\n",
    "\n",
    "-0.51    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e10b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3778995c",
   "metadata": {},
   "source": [
    "Missing value\n",
    "NA bucket can be merged with -\n",
    "\n",
    "\n",
    "1-1 Bucket\n",
    "\n",
    "2-2 Bucket\n",
    "\n",
    "7-9 Bucket\n",
    "\n",
    "None   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba31ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7007be4",
   "metadata": {},
   "source": [
    "## Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7617ea1",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "What do you infer from the woe plot of the 'Grade' variable?\n",
    "\n",
    "\n",
    "As the loan grade varies from A to G, the woe values gradually decrease from +0.99 to -1.09    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75d240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59694f6e",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "Choose the correct option:\n",
    "\n",
    "\n",
    "Woe graph shows monotonic nature    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458cf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ddf17e",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "Information value of the 'Grade' variable is:\n",
    "\n",
    "\n",
    "0.56\n",
    "\n",
    "0.43\n",
    "\n",
    "0.34    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4818324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e0f3a1",
   "metadata": {},
   "source": [
    "# Logistic Regression: Industry Applications - Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795ca80",
   "metadata": {},
   "source": [
    "## Coding Practice (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fibonacci Series\n",
    "Description\n",
    "Compute and display Fibonacci series upto n terms where n is a positive integer entered by the user.\n",
    "You can go here to read about Fibonacci series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(input())\n",
    "# first two terms\n",
    "n1, n2 = 0, 1\n",
    "count = 0\n",
    "\n",
    "# check if the number of terms is valid\n",
    "if n <= 0:\n",
    "   print(\"Please enter a positive integer\")\n",
    "# if there is only one term, return n1\n",
    "elif n == 1:\n",
    "   print(\"Fibonacci sequence upto\",nterms,\":\")\n",
    "   print(n1)\n",
    "# generate fibonacci sequence\n",
    "else:\n",
    "   print(\"Fibonacci sequence:\")\n",
    "   while count < n:\n",
    "       print(n1)\n",
    "       nth = n1 + n2\n",
    "       # update values\n",
    "       n1 = n2\n",
    "       n2 = nth\n",
    "       count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9b7c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prime Numbers\n",
    "Description\n",
    "Determine whether a positive integer n is a prime number or not. Assume n>1.\n",
    "Display “number entered is prime” if n is prime, otherwise display “number entered is not prime”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(input())\n",
    "out=True\n",
    "for i in range(2,n):\n",
    "    if(n%i==0):\n",
    "        out=False\n",
    "        break\n",
    "if out==True:\n",
    "    print(\"number entered is prime\")\n",
    "else:\n",
    "    print(\"number entered is not prime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbf2fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Armstrong number\n",
    "Description\n",
    "Any number, say n is called an Armstrong number if it is equal to the sum of its digits, where each is raised to the power of number of digits in n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(input())\n",
    "# Python program to check if the number is an Armstrong number or not\n",
    "# initialize sum\n",
    "sum = 0\n",
    "\n",
    "# find the sum of the cube of each digit\n",
    "temp = n\n",
    "while temp > 0:\n",
    "   digit = temp % 10\n",
    "   sum += digit ** 3\n",
    "   temp //= 10\n",
    "\n",
    "# display the result\n",
    "if n == sum:\n",
    "   print(True)\n",
    "else:\n",
    "   print(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673bb3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selecting dataframe columns\n",
    "Description\n",
    "Write a program to select all columns of a dataframe except the ones specified.\n",
    "The input will contain a list of columns that you should skip.\n",
    "You should print the first five rows of the dataframe as output where the columns are alphabetically sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast,sys\n",
    "df=pd.read_csv(\"https://media-doselect.s3.amazonaws.com/generic/X0kvr3wEYXRzONE5W37xWWYYA/test.csv\")\n",
    "input_str = sys.stdin.read()\n",
    "to_omit = ast.literal_eval(input_str)\n",
    "#write your code here\n",
    "df=df[df.columns[~df.columns.isin(to_omit)]]       ####  check before submit\n",
    "print(df.loc[:, sorted(list(df.columns))].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b2991",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two series\n",
    "Description\n",
    "Given two pandas series, find the position of elements in series2 in series1.\n",
    "You can assume that all elements in series2 will be present in series1.\n",
    "The input will contain two lines with series1 and series2 respectively.\n",
    "The output should be a list of indexes indicating elements of series2 in series 1.\n",
    "Note: In the output list, the indexes should be in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast,sys\n",
    "import pandas as pd\n",
    "input_str = sys.stdin.read()\n",
    "input_list = ast.literal_eval(input_str)\n",
    "series1=pd.Series(input_list[0])\n",
    "series2=pd.Series(input_list[1])\n",
    "out_list=[pd.Index(series1).get_loc(num) for num in series2]\n",
    "print(list(map(int,out_list)))#do not alter this step, list must be int type for evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7ad46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning columns\n",
    "Description\n",
    "For the given dataframe, you have to clean the \"Installs\" column and print its correlation with other numeric columns of the dataframe.(print df.corr())\n",
    "You have to do the following:\n",
    "1. Remove characters like ',' from the number of installs.\n",
    "2. Delete rows where the Installs column has irrelevant strings like 'Free'\n",
    "3. Convert the column to int type\n",
    "You can access the dataframe using the following URL in your Jupyter notebook:\n",
    "https://media-doselect.s3.amazonaws.com/generic/8NMooe4G0ENEe8z9q5ZvaZA7/googleplaystore.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf637e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv(\"https://media-doselect.s3.amazonaws.com/generic/8NMooe4G0ENEe8z9q5ZvaZA7/googleplaystore.csv\")\n",
    "\n",
    "df.Installs=df.Installs.str.replace(',','')\n",
    "\n",
    "df.Installs=df.Installs.str.replace('+','')\n",
    "df=df[df.Installs!='Free']\n",
    "\n",
    "df.Installs=df.Installs.astype(int)\n",
    "\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129dd750",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff45f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988d44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad7df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d124109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"ashutoshgole18/module-3-logistic-regression\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/ashutoshgole18/module-3-logistic-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/ashutoshgole18/module-3-logistic-regression'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1c69b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
